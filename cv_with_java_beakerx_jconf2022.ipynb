{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "228d1a0f",
   "metadata": {},
   "source": [
    "## Computer Vision con Java, TensorFlow y Jupyter - JConf 2022.\n",
    "\n",
    "\n",
    "En esta charla aprenderemos como integrar Java con el famoso notebook de desarrollo de datascience, AI y ML llamado Jupyter.\n",
    "\n",
    "**Por que Java para Machine Learning?**\n",
    "\n",
    "Java es un lenguaje que ha ido evolucionando con el tiempo y ha ido incorporando muchas innovaciones y en particular en el area de inteligencia artificial, muestra de ello es el JSR 381 para deteccion de objetos e imagenes con Machine Learning (mas informacion [aqui](https://www.jcp.org/en/jsr/detail?id=381))\n",
    "\n",
    "Por su parte Google tambien no se ha quedado atras y desarrollo una API de Tensorflow para Java desde los inicios de esta libreria, llamada libtensorflow: \n",
    "\n",
    "- Esta libreria fue perdiendo relevancia por el poco uso que se le daba debido al auge de Python en el area de DS y AI. \n",
    "- Con el auge del JSR 381 y el interes de la comunidad de Java de usarlo en ambientes de AI y ML Google comenzo con una nueva API de Tensorflow para Java, la tensorflow-core-platform.\n",
    "- Google comenzo ya a descontinuar la antigua libtensorflow. Actualmente la nueva API esta en etapa experimental (alpha)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b6376d8",
   "metadata": {},
   "source": [
    "## Stack que utilizaremos.\n",
    "\n",
    "Necesitaremos el siguiente stack:\n",
    "- **Anaconda: https://www.anaconda.com.** Es una distribucion de software de DataScience, AI y Analiticas que contiene un conjunto de librerias escritas en python para desarrollar aplicaciones.\n",
    "- **JDK u OpenJDK (segun su preferencia) de Java https://www.oracle.com/java/technologies/downloads/.** El Java Developer Kit para ejecutar y desarrollar aplicaciones en Java.\n",
    "- **Jupyter notebook (Obtenido por el manejador de paquetes conda en Anaconda).** Este es un notebook interactivo para desarrollar y evaluar aplicaciones cientificas u otras que manejen datos. Por default utiliza el kernel de python basado en la aplicacion ipython.\n",
    "- **BeakerX Jupyter kernel (Obtenido por el manejador de paquetes conda en Anaconda).** Beakerx es un jupyter kernel desarrollado de manera open source por la compania Two-Sigma la cual es una compania de tecnologia de datos e inteligencia artificial enfocada en el ambito financiero. El kernel es un kernel poliglota que soporta multiples lenguajes desde Python hasta Java, e incluso ofrece integracion con ApacheSpark para tambien desarrollar sistemas de Big Data y ML.\n",
    "- **tensorflow-core-api y tensorflow-framework** (instalados via Maven en Jupyter, ver mas abajo). La libreria de Machine Learning y computo cientifico de Google."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a7a331",
   "metadata": {},
   "source": [
    "### Instalacion de Anaconda y JDK.\n",
    "\n",
    "El proceso de instalacion es sencillo en este caso, solo basta con descargar el ejecutable de ambas aplicaciones, hacer doble clic en el y seguir los pasos de instalacion. Esto aplica para todas las plataformas (Linux, macOS y Windows)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d322eaf0",
   "metadata": {},
   "source": [
    "### Instalacion de Jupyter y BeakerX.\n",
    "\n",
    "Creamos un conda environment llamado beakerx:\n",
    "\n",
    "`$ conda create -y -n beakerx 'python>=3'`\n",
    "\n",
    "Activamos el environment de beakerx de la siguiente manera:\n",
    "\n",
    "`$ conda activate beakerx`\n",
    "\n",
    "Notara que el prompt de su terminal cambiara a `(beakerx)$` indicando que se ha cambiado correctamente al environment de beakerx.\n",
    "\n",
    "Configuramos el environment para que apunte al OpenJDK o JDK que usted tiene en su maquina (en mi caso tengo el JDK v18);\n",
    "\n",
    "`(beakerx)$ conda config --env --add pinned_packages 'jdk>8.0.121'`.\n",
    "\n",
    "Instalamos Jupyter y Beakerx:\n",
    "\n",
    "`(beakerx)$ conda install -y -c conda-forge ipywidgets beakerx`\n",
    "\n",
    "Para correr jupyter con beakerx:\n",
    "\n",
    "`(beakerx)$ jupyter notebook`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e641e4c2",
   "metadata": {},
   "source": [
    "### Instalando Google Tensorflow desde Maven\n",
    "\n",
    "Utilizamos el jupyter magic %classpath para instalar y precompilar a traves de maven la libreria de Google Tensorflow Java API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4472b90d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "method": "display_data"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95c8e243-11ba-4f27-95d0-190446f1e162",
       "version_major": 2,
       "version_minor": 0
      },
      "method": "display_data"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "method": "display_data"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7d6b7a0-40c4-4f99-806e-6978135e080f",
       "version_major": 2,
       "version_minor": 0
      },
      "method": "display_data"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%classpath add mvn org.tensorflow:tensorflow-core-platform:0.4.1\n",
    "%classpath add mvn org.tensorflow:tensorflow-framework:0.4.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57de4b06",
   "metadata": {},
   "source": [
    "### Creando una clase on los metodos para manejar el dataset de imagenes.\n",
    "\n",
    "El dataset que estaremos usando aca es el dataset del MNIST (mas info aqui: http://yann.lecun.com/exdb/mnist/) que tiene imagenes de digitos del 0 al 9 escritos a mano. El modelo se entrenara de manera que pueda reconocer una imagen de un digito manuscrito y decir que digito es ese.\n",
    "\n",
    "Con esta clase podremos tener todos los metodos/funciones que necesitamos para manejar el dataset de imagenes y tambien podemos generar la lista de archivos de entrenamiento (training set), archivos de prueba (test set).\n",
    "\n",
    "\n",
    "![MNIST](https://upload.wikimedia.org/wikipedia/commons/2/27/MnistExamples.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "054a9222",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "com.twosigma.beaker.javash.bkr572f4c5e.ImageBatchIterator"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import static org.tensorflow.ndarray.index.Indices.range;\n",
    "import java.util.Iterator;\n",
    "import org.tensorflow.ndarray.index.Index;\n",
    "import org.tensorflow.ndarray.ByteNdArray;\n",
    "import org.tensorflow.ndarray.index.Index;\n",
    "import org.tensorflow.ndarray.Shape;\n",
    "import org.tensorflow.ndarray.buffer.DataBuffers;\n",
    "import org.tensorflow.ndarray.ByteNdArray;\n",
    "import org.tensorflow.ndarray.NdArrays;\n",
    "import java.io.DataInputStream;\n",
    "import java.io.IOException;\n",
    "import java.util.zip.GZIPInputStream;\n",
    "import static org.tensorflow.ndarray.index.Indices.sliceFrom;\n",
    "import static org.tensorflow.ndarray.index.Indices.sliceTo;\n",
    "\n",
    "/** Basic batch iterator across images presented in datset. */\n",
    "class ImageBatchIterator implements Iterator<ImageBatch> {\n",
    "\n",
    "  @Override\n",
    "  public boolean hasNext() {\n",
    "    return batchStart < numImages;\n",
    "  }\n",
    "\n",
    "  @Override\n",
    "  public ImageBatch next() {\n",
    "    long nextBatchSize = Math.min(batchSize, numImages - batchStart);\n",
    "    Index range = range(batchStart, batchStart + nextBatchSize);\n",
    "    batchStart += nextBatchSize;\n",
    "    return new ImageBatch(images.slice(range), labels.slice(range));\n",
    "  }\n",
    "\n",
    "  public ImageBatchIterator(int batchSize, ByteNdArray images, ByteNdArray labels) {\n",
    "    this.batchSize = batchSize;\n",
    "    this.images = images;\n",
    "    this.labels = labels;\n",
    "    this.numImages = images != null ? images.shape().size(0) : 0;\n",
    "    this.batchStart = 0;\n",
    "  }\n",
    "\n",
    "  private final int batchSize;\n",
    "  private final ByteNdArray images;\n",
    "  private final ByteNdArray labels;\n",
    "  private final long numImages;\n",
    "  private int batchStart;\n",
    "}\n",
    "\n",
    "class ImageBatch {\n",
    "  \n",
    "  public ByteNdArray images() {\n",
    "    return images;\n",
    "  }\n",
    "  \n",
    "  public ByteNdArray labels() {\n",
    "    return labels;\n",
    "  }\n",
    "\n",
    "  public ImageBatch(ByteNdArray images, ByteNdArray labels) {\n",
    "    this.images = images;\n",
    "    this.labels = labels;\n",
    "  }\n",
    "\n",
    "  private final ByteNdArray images;\n",
    "  private final ByteNdArray labels;\n",
    "}\n",
    "\n",
    "\n",
    "class MnistDataset {\n",
    "  public static final int NUM_CLASSES = 10;\n",
    "\n",
    "  public static MnistDataset create(int validationSize, String trainingImagesArchive, String trainingLabelsArchive,\n",
    "                                    String testImagesArchive, String testLabelsArchive) {\n",
    "    try {\n",
    "      System.out.println(trainingImagesArchive);\n",
    "      ByteNdArray trainingImages = readArchive(trainingImagesArchive);\n",
    "      ByteNdArray trainingLabels = readArchive(trainingLabelsArchive);\n",
    "      ByteNdArray testImages = readArchive(testImagesArchive);\n",
    "      ByteNdArray testLabels = readArchive(testLabelsArchive);\n",
    "      ByteNdArray empty;\n",
    "\n",
    "      if (validationSize > 0) {\n",
    "        return new MnistDataset(\n",
    "            trainingImages.slice(sliceFrom(validationSize)),\n",
    "            trainingLabels.slice(sliceFrom(validationSize)),\n",
    "            trainingImages.slice(sliceTo(validationSize)),\n",
    "            trainingLabels.slice(sliceTo(validationSize)),\n",
    "            testImages,\n",
    "            testLabels\n",
    "        );\n",
    "      }\n",
    "      \n",
    "      return new MnistDataset(trainingImages, trainingLabels, null, null, testImages, testLabels);\n",
    "      \n",
    "\n",
    "    } catch (IOException e) {\n",
    "        throw new AssertionError(e);\n",
    "    }\n",
    "  }\n",
    "\n",
    "  public Iterable<ImageBatch> trainingBatches(int batchSize) {\n",
    "    return () -> new ImageBatchIterator(batchSize, trainingImages, trainingLabels);\n",
    "  }\n",
    "\n",
    "  public Iterable<ImageBatch> validationBatches(int batchSize) {\n",
    "    return () -> new ImageBatchIterator(batchSize, validationImages, validationLabels);\n",
    "  }\n",
    "\n",
    "  public Iterable<ImageBatch> testBatches(int batchSize) {\n",
    "    return () -> new ImageBatchIterator(batchSize, testImages, testLabels);\n",
    "  }\n",
    "\n",
    "  public ImageBatch testBatch() {\n",
    "    return new ImageBatch(testImages, testLabels);\n",
    "  }\n",
    "\n",
    "  public long imageSize() {\n",
    "    return imageSize;\n",
    "  }\n",
    "\n",
    "  public long numTrainingExamples() {\n",
    "    return trainingLabels.shape().size(0);\n",
    "  }\n",
    "\n",
    "  public long numTestingExamples() {\n",
    "    return testLabels.shape().size(0);\n",
    "  }\n",
    "\n",
    "  public long numValidationExamples() {\n",
    "    return validationLabels.shape().size(0);\n",
    "  }\n",
    "\n",
    "  private static final int TYPE_UBYTE = 0x08;\n",
    "\n",
    "  private final ByteNdArray trainingImages;\n",
    "  private final ByteNdArray trainingLabels;\n",
    "  private final ByteNdArray validationImages;\n",
    "  private final ByteNdArray validationLabels;\n",
    "  private final ByteNdArray testImages;\n",
    "  private final ByteNdArray testLabels;\n",
    "  private final long imageSize;\n",
    "\n",
    "  private MnistDataset(\n",
    "      ByteNdArray trainingImages,\n",
    "      ByteNdArray trainingLabels,\n",
    "      ByteNdArray validationImages,\n",
    "      ByteNdArray validationLabels,\n",
    "      ByteNdArray testImages,\n",
    "      ByteNdArray testLabels\n",
    "  ) {\n",
    "    this.trainingImages = trainingImages;\n",
    "    this.trainingLabels = trainingLabels;\n",
    "    this.validationImages = validationImages;\n",
    "    this.validationLabels = validationLabels;\n",
    "    this.testImages = testImages;\n",
    "    this.testLabels = testLabels;\n",
    "    this.imageSize = trainingImages.get(0).shape().size();\n",
    "  }\n",
    "\n",
    "  private static ByteNdArray readArchive(String archiveName) throws IOException {\n",
    "    DataInputStream archiveStream = new DataInputStream(\n",
    "        //new GZIPInputStream(new java.io.FileInputStream(\"src/main/resources/\"+archiveName))\n",
    "        new GZIPInputStream(new java.io.FileInputStream(archiveName))\n",
    "    );\n",
    "    archiveStream.readShort(); // first two bytes are always 0\n",
    "    byte magic = archiveStream.readByte();\n",
    "    if (magic != TYPE_UBYTE) {\n",
    "      throw new IllegalArgumentException(\"\\\"\" + archiveName + \"\\\" is not a valid archive\");\n",
    "    }\n",
    "    int numDims = archiveStream.readByte();\n",
    "    long[] dimSizes = new long[numDims];\n",
    "    int size = 1;  // for simplicity, we assume that total size does not exceeds Integer.MAX_VALUE\n",
    "    \n",
    "    for (int i = 0; i < dimSizes.length; ++i) {\n",
    "      dimSizes[i] = archiveStream.readInt();\n",
    "      size *= dimSizes[i];\n",
    "    }\n",
    "    \n",
    "    byte[] bytes = new byte[size];\n",
    "    archiveStream.readFully(bytes);\n",
    "    return NdArrays.wrap(Shape.of(dimSizes), DataBuffers.of(bytes, true, false));\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "918d69c6",
   "metadata": {},
   "source": [
    "### Red Neuronal Convolucional (CNN).\n",
    "\n",
    "Una red neuronal convolucional es un tipo de red neuronal muy usado en Inteligencia Artificial para variadas aplicaciones, entre ellas la mas popular la clasificiacion o reconocimiento de imagenes. Utiliza el mecanismo de deep learning (aprendizaje profundo) porque la red neuronal se compone de varias capas que secuencialmente van pasando la salida de una hacia la entrada de la otra, donde cada capa se enfoca en extraer algun tipo de feature o caracteristica del dato que se esta aprendiendo. El tipo de aprendizaje que estamos aplicando es aprendizaje supervisado (Supervised Learning) porque le estamos dando los datos y las etiquetas de cada uno para que la maquina aprenda a identificarlos.\n",
    "\n",
    "![CNN](https://editor.analyticsvidhya.com/uploads/59954intro%20to%20CNN.JPG)\n",
    "![Filters](https://www.baeldung.com/wp-content/uploads/sites/4/2022/03/conv.png)\n",
    "![OneHot encoding](https://miro.medium.com/max/1400/1*ggtP4a5YaRx6l09KQaYOnw.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ed3b4e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import java.util.Arrays;\n",
    "import java.util.logging.Level;\n",
    "import java.util.logging.Logger;\n",
    "import org.tensorflow.Graph;\n",
    "import org.tensorflow.Operand;\n",
    "import org.tensorflow.Session;\n",
    "import org.tensorflow.framework.optimizers.AdaDelta;\n",
    "import org.tensorflow.framework.optimizers.AdaGrad;\n",
    "import org.tensorflow.framework.optimizers.AdaGradDA;\n",
    "import org.tensorflow.framework.optimizers.Adam;\n",
    "import org.tensorflow.framework.optimizers.GradientDescent;\n",
    "import org.tensorflow.framework.optimizers.Momentum;\n",
    "import org.tensorflow.framework.optimizers.Optimizer;\n",
    "import org.tensorflow.framework.optimizers.RMSProp;\n",
    "import org.tensorflow.ndarray.ByteNdArray;\n",
    "import org.tensorflow.ndarray.FloatNdArray;\n",
    "import org.tensorflow.ndarray.Shape;\n",
    "import org.tensorflow.ndarray.index.Indices;\n",
    "import org.tensorflow.op.Op;\n",
    "import org.tensorflow.op.Ops;\n",
    "import org.tensorflow.op.core.Constant;\n",
    "import org.tensorflow.op.core.OneHot;\n",
    "import org.tensorflow.op.core.Placeholder;\n",
    "import org.tensorflow.op.core.Reshape;\n",
    "import org.tensorflow.op.core.Variable;\n",
    "import org.tensorflow.op.math.Add;\n",
    "import org.tensorflow.op.math.Mean;\n",
    "import org.tensorflow.op.nn.Conv2d;\n",
    "import org.tensorflow.op.nn.MaxPool;\n",
    "import org.tensorflow.op.nn.Relu;\n",
    "import org.tensorflow.op.nn.Softmax;\n",
    "import org.tensorflow.op.nn.SoftmaxCrossEntropyWithLogits;\n",
    "import org.tensorflow.op.random.TruncatedNormal;\n",
    "import org.tensorflow.types.TFloat32;\n",
    "import org.tensorflow.types.TUint8;\n",
    "\n",
    "\n",
    "public class CnnMnist {\n",
    "\n",
    "  private static final Logger logger = Logger.getLogger(CnnMnist.class.getName());\n",
    "\n",
    "  private static final int PIXEL_DEPTH = 255;\n",
    "  private static final int NUM_CHANNELS = 1;\n",
    "  private static final int IMAGE_SIZE = 28;\n",
    "  private static final int NUM_LABELS = MnistDataset.NUM_CLASSES;\n",
    "  private static final long SEED = 123456789L;\n",
    "\n",
    "  private static final String PADDING_TYPE = \"SAME\";\n",
    "\n",
    "  public static final String INPUT_NAME = \"input\";\n",
    "  public static final String OUTPUT_NAME = \"output\";\n",
    "  public static final String TARGET = \"target\";\n",
    "  public static final String TRAIN = \"train\";\n",
    "  public static final String TRAINING_LOSS = \"training_loss\";\n",
    "\n",
    "  public static Graph build(String optimizerName) {\n",
    "    Graph graph = new Graph();\n",
    "\n",
    "    Ops tf = Ops.create(graph);\n",
    "\n",
    "    // Inputs\n",
    "    Placeholder<TUint8> input = tf.withName(INPUT_NAME).placeholder(TUint8.class,\n",
    "        Placeholder.shape(Shape.of(-1, IMAGE_SIZE, IMAGE_SIZE)));\n",
    "    Reshape<TUint8> input_reshaped = tf\n",
    "        .reshape(input, tf.array(-1, IMAGE_SIZE, IMAGE_SIZE, NUM_CHANNELS));\n",
    "    Placeholder<TUint8> labels = tf.withName(TARGET).placeholder(TUint8.class);\n",
    "\n",
    "    // Scaling the features we must make sure that images are properly centered and scaled to the same size.\n",
    "    Constant<TFloat32> centeringFactor = tf.constant(PIXEL_DEPTH / 2.0f);\n",
    "    Constant<TFloat32> scalingFactor = tf.constant((float) PIXEL_DEPTH);\n",
    "    Operand<TFloat32> scaledInput = tf.math\n",
    "        .div(tf.math.sub(tf.dtypes.cast(input_reshaped, TFloat32.class), centeringFactor),\n",
    "            scalingFactor);\n",
    "\n",
    "    // First conv layer\n",
    "    Variable<TFloat32> conv1Weights = tf.variable(tf.math.mul(tf.random\n",
    "        .truncatedNormal(tf.array(5, 5, NUM_CHANNELS, 32), TFloat32.class,\n",
    "            TruncatedNormal.seed(SEED)), tf.constant(0.1f)));\n",
    "    Conv2d<TFloat32> conv1 = tf.nn\n",
    "        .conv2d(scaledInput, conv1Weights, Arrays.asList(1L, 1L, 1L, 1L), PADDING_TYPE);\n",
    "    Variable<TFloat32> conv1Biases = tf\n",
    "        .variable(tf.fill(tf.array(new int[]{32}), tf.constant(0.0f)));\n",
    "    Relu<TFloat32> relu1 = tf.nn.relu(tf.nn.biasAdd(conv1, conv1Biases));\n",
    "\n",
    "    // First pooling layer\n",
    "    MaxPool<TFloat32> pool1 = tf.nn\n",
    "        .maxPool(relu1, tf.array(1, 2, 2, 1), tf.array(1, 2, 2, 1),\n",
    "            PADDING_TYPE);\n",
    "\n",
    "    // Second conv layer\n",
    "    Variable<TFloat32> conv2Weights = tf.variable(tf.math.mul(tf.random\n",
    "        .truncatedNormal(tf.array(5, 5, 32, 64), TFloat32.class,\n",
    "            TruncatedNormal.seed(SEED)), tf.constant(0.1f)));\n",
    "    Conv2d<TFloat32> conv2 = tf.nn\n",
    "        .conv2d(pool1, conv2Weights, Arrays.asList(1L, 1L, 1L, 1L), PADDING_TYPE);\n",
    "    Variable<TFloat32> conv2Biases = tf\n",
    "        .variable(tf.fill(tf.array(new int[]{64}), tf.constant(0.1f)));\n",
    "    Relu<TFloat32> relu2 = tf.nn.relu(tf.nn.biasAdd(conv2, conv2Biases));\n",
    "\n",
    "    // Second pooling layer\n",
    "    MaxPool<TFloat32> pool2 = tf.nn\n",
    "        .maxPool(relu2, tf.array(1, 2, 2, 1), tf.array(1, 2, 2, 1),\n",
    "            PADDING_TYPE);\n",
    "\n",
    "    // Flatten inputs\n",
    "    Reshape<TFloat32> flatten = tf.reshape(pool2, tf.concat(Arrays\n",
    "        .asList(tf.slice(tf.shape(pool2), tf.array(new int[]{0}), tf.array(new int[]{1})),\n",
    "            tf.array(new int[]{-1})), tf.constant(0)));\n",
    "\n",
    "    // Fully connected layer\n",
    "    Variable<TFloat32> fc1Weights = tf.variable(tf.math.mul(tf.random\n",
    "        .truncatedNormal(tf.array(IMAGE_SIZE * IMAGE_SIZE * 4, 512), TFloat32.class,\n",
    "            TruncatedNormal.seed(SEED)), tf.constant(0.1f)));\n",
    "    Variable<TFloat32> fc1Biases = tf\n",
    "        .variable(tf.fill(tf.array(new int[]{512}), tf.constant(0.1f)));\n",
    "    Relu<TFloat32> relu3 = tf.nn\n",
    "        .relu(tf.math.add(tf.linalg.matMul(flatten, fc1Weights), fc1Biases));\n",
    "\n",
    "    // Softmax layer\n",
    "    Variable<TFloat32> fc2Weights = tf.variable(tf.math.mul(tf.random\n",
    "        .truncatedNormal(tf.array(512, NUM_LABELS), TFloat32.class,\n",
    "            TruncatedNormal.seed(SEED)), tf.constant(0.1f)));\n",
    "    Variable<TFloat32> fc2Biases = tf\n",
    "        .variable(tf.fill(tf.array(new int[]{NUM_LABELS}), tf.constant(0.1f)));\n",
    "\n",
    "    Add<TFloat32> logits = tf.math.add(tf.linalg.matMul(relu3, fc2Weights), fc2Biases);\n",
    "\n",
    "    // Predicted outputs\n",
    "    Softmax<TFloat32> prediction = tf.withName(OUTPUT_NAME).nn.softmax(logits);\n",
    "\n",
    "    // Loss function & regularization\n",
    "    OneHot<TFloat32> oneHot = tf\n",
    "        .oneHot(labels, tf.constant(10), tf.constant(1.0f), tf.constant(0.0f));\n",
    "    SoftmaxCrossEntropyWithLogits<TFloat32> batchLoss = tf.nn.softmaxCrossEntropyWithLogits(logits, oneHot);\n",
    "    Mean<TFloat32> labelLoss = tf.math.mean(batchLoss.loss(), tf.constant(0));\n",
    "    Add<TFloat32> regularizers = tf.math.add(tf.nn.l2Loss(fc1Weights), tf.math\n",
    "        .add(tf.nn.l2Loss(fc1Biases),\n",
    "            tf.math.add(tf.nn.l2Loss(fc2Weights), tf.nn.l2Loss(fc2Biases))));\n",
    "    Add<TFloat32> loss = tf.withName(TRAINING_LOSS).math\n",
    "        .add(labelLoss, tf.math.mul(regularizers, tf.constant(5e-4f)));\n",
    "\n",
    "    String lcOptimizerName = optimizerName.toLowerCase();\n",
    "    // Optimizer\n",
    "    Optimizer optimizer;\n",
    "    switch (lcOptimizerName) {\n",
    "      case \"adadelta\":\n",
    "        optimizer = new AdaDelta(graph, 1f, 0.95f, 1e-8f);\n",
    "        break;\n",
    "      case \"adagradda\":\n",
    "        optimizer = new AdaGradDA(graph, 0.01f);\n",
    "        break;\n",
    "      case \"adagrad\":\n",
    "        optimizer = new AdaGrad(graph, 0.01f);\n",
    "        break;\n",
    "      case \"adam\":\n",
    "        optimizer = new Adam(graph, 0.001f, 0.9f, 0.999f, 1e-8f);\n",
    "        break;\n",
    "      case \"sgd\":\n",
    "        optimizer = new GradientDescent(graph, 0.01f);\n",
    "        break;\n",
    "      case \"momentum\":\n",
    "        optimizer = new Momentum(graph, 0.01f, 0.9f, false);\n",
    "        break;\n",
    "      case \"rmsprop\":\n",
    "        optimizer = new RMSProp(graph, 0.01f, 0.9f, 0.0f, 1e-10f, false);\n",
    "        break;\n",
    "      default:\n",
    "        throw new IllegalArgumentException(\"Unknown optimizer \" + optimizerName);\n",
    "    }\n",
    "    logger.info(\"Optimizer = \" + optimizer);\n",
    "    Op minimize = optimizer.minimize(loss, TRAIN);\n",
    "\n",
    "    return graph;\n",
    "  }\n",
    "\n",
    "  public static void train(Session session, int epochs, int minibatchSize, MnistDataset dataset) {\n",
    "    int interval = 0;\n",
    "    // Train the model\n",
    "    for (int i = 0; i < epochs; i++) {\n",
    "      for (ImageBatch trainingBatch : dataset.trainingBatches(minibatchSize)) {\n",
    "        try (TUint8 batchImages = TUint8.tensorOf(trainingBatch.images());\n",
    "            TUint8 batchLabels = TUint8.tensorOf(trainingBatch.labels());\n",
    "            TFloat32 loss = (TFloat32)session.runner()\n",
    "                .feed(TARGET, batchLabels)\n",
    "                .feed(INPUT_NAME, batchImages)\n",
    "                .addTarget(TRAIN)\n",
    "                .fetch(TRAINING_LOSS)\n",
    "                .run().get(0)) {\n",
    "          if (interval % 100 == 0) {\n",
    "            logger.log(Level.INFO,\n",
    "                \"Iteration = \" + interval + \", training loss = \" + loss.getFloat());\n",
    "          }\n",
    "        }\n",
    "        interval++;\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "\n",
    "  public static void test(Session session, int minibatchSize, MnistDataset dataset) {\n",
    "    int correctCount = 0;\n",
    "    int[][] confusionMatrix = new int[10][10];\n",
    "\n",
    "    for (ImageBatch trainingBatch : dataset.testBatches(minibatchSize)) {\n",
    "      try (TUint8 transformedInput = TUint8.tensorOf(trainingBatch.images());\n",
    "          TFloat32 outputTensor = (TFloat32)session.runner()\n",
    "              .feed(INPUT_NAME, transformedInput)\n",
    "              .fetch(OUTPUT_NAME).run().get(0)) {\n",
    "\n",
    "        ByteNdArray labelBatch = trainingBatch.labels();\n",
    "        for (int k = 0; k < labelBatch.shape().size(0); k++) {\n",
    "          byte trueLabel = labelBatch.getByte(k);\n",
    "          int predLabel;\n",
    "\n",
    "          predLabel = argmax(outputTensor.slice(Indices.at(k), Indices.all()));\n",
    "          if (predLabel == trueLabel) {\n",
    "            correctCount++;\n",
    "          }\n",
    "\n",
    "          confusionMatrix[trueLabel][predLabel]++;\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "\n",
    "    logger.info(\"Final accuracy = \" + ((float) correctCount) / dataset.numTestingExamples());\n",
    "\n",
    "    StringBuilder sb = new StringBuilder();\n",
    "    sb.append(\"Label\");\n",
    "    for (int i = 0; i < confusionMatrix.length; i++) {\n",
    "      sb.append(String.format(\"%1$5s\", \"\" + i));\n",
    "    }\n",
    "    sb.append(\"\\n\");\n",
    "\n",
    "    for (int i = 0; i < confusionMatrix.length; i++) {\n",
    "      sb.append(String.format(\"%1$5s\", \"\" + i));\n",
    "      for (int j = 0; j < confusionMatrix[i].length; j++) {\n",
    "        sb.append(String.format(\"%1$5s\", \"\" + confusionMatrix[i][j]));\n",
    "      }\n",
    "      sb.append(\"\\n\");\n",
    "    }\n",
    "\n",
    "    System.out.println(sb);\n",
    "  }\n",
    "\n",
    "  \n",
    "  public static int argmax(FloatNdArray probabilities) {\n",
    "    float maxVal = Float.NEGATIVE_INFINITY;\n",
    "    int idx = 0;\n",
    "    for (int i = 0; i < probabilities.shape().size(0); i++) {\n",
    "      float curVal = probabilities.getFloat(i);\n",
    "      if (curVal > maxVal) {\n",
    "        maxVal = curVal;\n",
    "        idx = i;\n",
    "      }\n",
    "    }\n",
    "    return idx;\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d550619",
   "metadata": {},
   "source": [
    "### Entrenando la red neuronal\n",
    "\n",
    "En los siguientes pasos entrenaremos la red neuronal utilizando 10 epochs o iteraciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcaad0f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current directory: /Users/juanjpolanco/Documents/CV_with_Java/cv-tensorflow-jupyter-java-jconf2022/\n",
      "/Users/juanjpolanco/Documents/CV_with_Java/cv-tensorflow-jupyter-java-jconf2022/mnist-dataset/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Aug 03, 2022 10:07:32 PM com.twosigma.beaker.javash.bkr572f4c5e.BeakerWrapperClass1261714175Id967e7e312e6f4edb8e5ba46c66cd30d6 beakerRun\n",
      "INFO: Loaded data.\n",
      "Aug 03, 2022 10:07:35 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist build\n",
      "INFO: Optimizer = RMSProp{learningRate=0.01, decay=0.9, momentum=0.0, epsilon=1.0E-10, centered=false}\n",
      "Aug 03, 2022 10:07:35 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 0, training loss = 6.570856\n",
      "Aug 03, 2022 10:07:37 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 100, training loss = 4.7705083\n",
      "Aug 03, 2022 10:07:39 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 200, training loss = 0.75649226\n",
      "Aug 03, 2022 10:07:40 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 300, training loss = 0.40414923\n",
      "Aug 03, 2022 10:07:42 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 400, training loss = 0.31215405\n",
      "Aug 03, 2022 10:07:44 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 500, training loss = 0.20782226\n",
      "Aug 03, 2022 10:07:45 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 600, training loss = 0.42091805\n",
      "Aug 03, 2022 10:07:47 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 700, training loss = 2.341665\n",
      "Aug 03, 2022 10:07:49 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 800, training loss = 0.14353044\n",
      "Aug 03, 2022 10:07:50 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 900, training loss = 0.12058523\n",
      "Aug 03, 2022 10:07:52 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 1000, training loss = 0.08873031\n",
      "Aug 03, 2022 10:07:53 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 1100, training loss = 0.07852488\n",
      "Aug 03, 2022 10:07:55 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 1200, training loss = 0.07727416\n",
      "Aug 03, 2022 10:07:57 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 1300, training loss = 0.103939205\n",
      "Aug 03, 2022 10:07:58 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 1400, training loss = 0.15072247\n",
      "Aug 03, 2022 10:08:00 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 1500, training loss = 0.08205722\n",
      "Aug 03, 2022 10:08:02 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 1600, training loss = 0.069999464\n",
      "Aug 03, 2022 10:08:03 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 1700, training loss = 0.10664953\n",
      "Aug 03, 2022 10:08:05 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 1800, training loss = 0.7506434\n",
      "Aug 03, 2022 10:08:06 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 1900, training loss = 0.40643328\n",
      "Aug 03, 2022 10:08:08 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 2000, training loss = 0.44488877\n",
      "Aug 03, 2022 10:08:09 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 2100, training loss = 0.05657212\n",
      "Aug 03, 2022 10:08:11 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 2200, training loss = 0.076155365\n",
      "Aug 03, 2022 10:08:13 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 2300, training loss = 0.060421437\n",
      "Aug 03, 2022 10:08:14 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 2400, training loss = 0.2864374\n",
      "Aug 03, 2022 10:08:16 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 2500, training loss = 0.05134778\n",
      "Aug 03, 2022 10:08:17 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 2600, training loss = 0.04881713\n",
      "Aug 03, 2022 10:08:19 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 2700, training loss = 0.045494635\n",
      "Aug 03, 2022 10:08:20 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 2800, training loss = 0.04246742\n",
      "Aug 03, 2022 10:08:22 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 2900, training loss = 0.059737504\n",
      "Aug 03, 2022 10:08:23 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 3000, training loss = 0.044019982\n",
      "Aug 03, 2022 10:08:25 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 3100, training loss = 0.046999812\n",
      "Aug 03, 2022 10:08:27 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 3200, training loss = 0.087653235\n",
      "Aug 03, 2022 10:08:28 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 3300, training loss = 0.22516435\n",
      "Aug 03, 2022 10:08:30 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 3400, training loss = 0.04030379\n",
      "Aug 03, 2022 10:08:31 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 3500, training loss = 0.04996107\n",
      "Aug 03, 2022 10:08:33 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 3600, training loss = 0.038120523\n",
      "Aug 03, 2022 10:08:34 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 3700, training loss = 0.03780594\n",
      "Aug 03, 2022 10:08:36 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 3800, training loss = 0.04441562\n",
      "Aug 03, 2022 10:08:38 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 3900, training loss = 0.041271493\n",
      "Aug 03, 2022 10:08:39 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 4000, training loss = 0.09945685\n",
      "Aug 03, 2022 10:08:41 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 4100, training loss = 0.067495584\n",
      "Aug 03, 2022 10:08:43 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 4200, training loss = 0.07883104\n",
      "Aug 03, 2022 10:08:44 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 4300, training loss = 0.09645368\n",
      "Aug 03, 2022 10:08:46 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 4400, training loss = 0.047428235\n",
      "Aug 03, 2022 10:08:47 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 4500, training loss = 0.050912187\n",
      "Aug 03, 2022 10:08:49 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 4600, training loss = 0.045099773\n",
      "Aug 03, 2022 10:08:50 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 4700, training loss = 1.1244001\n",
      "Aug 03, 2022 10:08:52 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 4800, training loss = 0.04234568\n",
      "Aug 03, 2022 10:08:54 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 4900, training loss = 0.5505494\n",
      "Aug 03, 2022 10:08:55 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 5000, training loss = 0.038328737\n",
      "Aug 03, 2022 10:08:57 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 5100, training loss = 0.06127114\n",
      "Aug 03, 2022 10:08:58 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 5200, training loss = 0.2561268\n",
      "Aug 03, 2022 10:09:00 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 5300, training loss = 0.043248307\n",
      "Aug 03, 2022 10:09:02 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 5400, training loss = 0.042108938\n",
      "Aug 03, 2022 10:09:03 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 5500, training loss = 0.042036593\n",
      "Aug 03, 2022 10:09:05 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 5600, training loss = 0.036104247\n",
      "Aug 03, 2022 10:09:07 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 5700, training loss = 0.059982143\n",
      "Aug 03, 2022 10:09:08 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 5800, training loss = 0.042318482\n",
      "Aug 03, 2022 10:09:10 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 5900, training loss = 0.028401019\n",
      "Aug 03, 2022 10:09:11 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 6000, training loss = 0.043371487\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Aug 03, 2022 10:09:13 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 6100, training loss = 0.05490373\n",
      "Aug 03, 2022 10:09:14 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 6200, training loss = 0.41990888\n",
      "Aug 03, 2022 10:09:16 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 6300, training loss = 0.16968188\n",
      "Aug 03, 2022 10:09:18 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 6400, training loss = 0.03487949\n",
      "Aug 03, 2022 10:09:19 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 6500, training loss = 0.037381288\n",
      "Aug 03, 2022 10:09:21 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 6600, training loss = 0.03453203\n",
      "Aug 03, 2022 10:09:22 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 6700, training loss = 0.2577493\n",
      "Aug 03, 2022 10:09:24 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 6800, training loss = 0.26543832\n",
      "Aug 03, 2022 10:09:25 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 6900, training loss = 0.08719173\n",
      "Aug 03, 2022 10:09:27 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 7000, training loss = 0.056535743\n",
      "Aug 03, 2022 10:09:28 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 7100, training loss = 0.037407674\n",
      "Aug 03, 2022 10:09:30 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 7200, training loss = 0.038790982\n",
      "Aug 03, 2022 10:09:32 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 7300, training loss = 0.050464142\n",
      "Aug 03, 2022 10:09:33 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 7400, training loss = 0.26999483\n",
      "Aug 03, 2022 10:09:35 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 7500, training loss = 0.035167504\n",
      "Aug 03, 2022 10:09:36 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 7600, training loss = 0.036159538\n",
      "Aug 03, 2022 10:09:38 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 7700, training loss = 0.052576892\n",
      "Aug 03, 2022 10:09:40 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 7800, training loss = 0.5408308\n",
      "Aug 03, 2022 10:09:41 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 7900, training loss = 0.22163916\n",
      "Aug 03, 2022 10:09:43 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 8000, training loss = 0.032842863\n",
      "Aug 03, 2022 10:09:44 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 8100, training loss = 0.04544847\n",
      "Aug 03, 2022 10:09:46 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 8200, training loss = 0.6434633\n",
      "Aug 03, 2022 10:09:47 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 8300, training loss = 0.032609455\n",
      "Aug 03, 2022 10:09:49 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 8400, training loss = 0.14899592\n",
      "Aug 03, 2022 10:09:51 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 8500, training loss = 0.047126666\n",
      "Aug 03, 2022 10:09:52 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 8600, training loss = 0.0328903\n",
      "Aug 03, 2022 10:09:54 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 8700, training loss = 0.033063572\n",
      "Aug 03, 2022 10:09:55 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 8800, training loss = 0.04625743\n",
      "Aug 03, 2022 10:09:57 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 8900, training loss = 0.03809316\n",
      "Aug 03, 2022 10:09:58 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 9000, training loss = 0.033861827\n",
      "Aug 03, 2022 10:10:00 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 9100, training loss = 0.064280085\n",
      "Aug 03, 2022 10:10:02 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 9200, training loss = 0.08707791\n",
      "Aug 03, 2022 10:10:03 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 9300, training loss = 0.25540042\n",
      "Aug 03, 2022 10:10:05 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 9400, training loss = 0.060978584\n",
      "Aug 03, 2022 10:10:06 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 9500, training loss = 0.0346766\n",
      "Aug 03, 2022 10:10:08 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 9600, training loss = 0.035190627\n",
      "Aug 03, 2022 10:10:09 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 9700, training loss = 0.7084147\n",
      "Aug 03, 2022 10:10:11 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 9800, training loss = 0.038205404\n",
      "Aug 03, 2022 10:10:13 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 9900, training loss = 0.033313535\n",
      "Aug 03, 2022 10:10:14 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 10000, training loss = 0.03399398\n",
      "Aug 03, 2022 10:10:16 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 10100, training loss = 0.03309318\n",
      "Aug 03, 2022 10:10:17 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 10200, training loss = 0.28452343\n",
      "Aug 03, 2022 10:10:19 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 10300, training loss = 0.15701722\n",
      "Aug 03, 2022 10:10:20 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 10400, training loss = 0.051039696\n",
      "Aug 03, 2022 10:10:22 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 10500, training loss = 0.034269303\n",
      "Aug 03, 2022 10:10:24 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 10600, training loss = 0.03614387\n",
      "Aug 03, 2022 10:10:25 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 10700, training loss = 0.9231917\n",
      "Aug 03, 2022 10:10:27 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 10800, training loss = 0.035981808\n",
      "Aug 03, 2022 10:10:28 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 10900, training loss = 0.033687104\n",
      "Aug 03, 2022 10:10:30 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 11000, training loss = 0.038331795\n",
      "Aug 03, 2022 10:10:31 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 11100, training loss = 0.048615754\n",
      "Aug 03, 2022 10:10:33 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 11200, training loss = 0.116102606\n",
      "Aug 03, 2022 10:10:35 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 11300, training loss = 0.034241043\n",
      "Aug 03, 2022 10:10:36 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 11400, training loss = 0.12529255\n",
      "Aug 03, 2022 10:10:38 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 11500, training loss = 0.079237685\n",
      "Aug 03, 2022 10:10:39 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 11600, training loss = 0.034560177\n",
      "Aug 03, 2022 10:10:41 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 11700, training loss = 0.085586846\n",
      "Aug 03, 2022 10:10:42 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 11800, training loss = 0.033544954\n",
      "Aug 03, 2022 10:10:44 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 11900, training loss = 0.028728042\n",
      "Aug 03, 2022 10:10:45 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 12000, training loss = 0.043451913\n",
      "Aug 03, 2022 10:10:47 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 12100, training loss = 0.15256211\n",
      "Aug 03, 2022 10:10:48 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 12200, training loss = 0.06782529\n",
      "Aug 03, 2022 10:10:50 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 12300, training loss = 0.12645057\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Aug 03, 2022 10:10:52 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 12400, training loss = 0.04647497\n",
      "Aug 03, 2022 10:10:53 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 12500, training loss = 0.5341081\n",
      "Aug 03, 2022 10:10:55 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 12600, training loss = 0.032085117\n",
      "Aug 03, 2022 10:10:56 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 12700, training loss = 0.21753564\n",
      "Aug 03, 2022 10:10:58 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 12800, training loss = 0.18725315\n",
      "Aug 03, 2022 10:10:59 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 12900, training loss = 0.05784621\n",
      "Aug 03, 2022 10:11:01 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 13000, training loss = 0.03305897\n",
      "Aug 03, 2022 10:11:02 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 13100, training loss = 0.22748049\n",
      "Aug 03, 2022 10:11:04 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 13200, training loss = 0.04291424\n",
      "Aug 03, 2022 10:11:05 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 13300, training loss = 0.16139255\n",
      "Aug 03, 2022 10:11:07 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 13400, training loss = 2.1033087\n",
      "Aug 03, 2022 10:11:09 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 13500, training loss = 0.033449188\n",
      "Aug 03, 2022 10:11:10 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 13600, training loss = 0.11950586\n",
      "Aug 03, 2022 10:11:12 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 13700, training loss = 0.036853362\n",
      "Aug 03, 2022 10:11:13 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 13800, training loss = 0.6889865\n",
      "Aug 03, 2022 10:11:15 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 13900, training loss = 0.2584144\n",
      "Aug 03, 2022 10:11:17 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 14000, training loss = 0.032691233\n",
      "Aug 03, 2022 10:11:18 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 14100, training loss = 0.056845047\n",
      "Aug 03, 2022 10:11:21 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 14300, training loss = 0.03941821\n",
      "Aug 03, 2022 10:11:23 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 14400, training loss = 0.10574765\n",
      "Aug 03, 2022 10:11:24 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 14500, training loss = 0.036494024\n",
      "Aug 03, 2022 10:11:26 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 14600, training loss = 0.031632397\n",
      "Aug 03, 2022 10:11:27 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 14700, training loss = 0.0322825\n",
      "Aug 03, 2022 10:11:29 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 14800, training loss = 0.029107282\n",
      "Aug 03, 2022 10:11:31 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 14900, training loss = 0.033161793\n",
      "Aug 03, 2022 10:11:32 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 15000, training loss = 0.032063875\n",
      "Aug 03, 2022 10:11:34 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 15100, training loss = 0.058828454\n",
      "Aug 03, 2022 10:11:35 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 15200, training loss = 0.036234897\n",
      "Aug 03, 2022 10:11:37 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 15300, training loss = 0.071958154\n",
      "Aug 03, 2022 10:11:38 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 15400, training loss = 0.031486206\n",
      "Aug 03, 2022 10:11:40 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 15500, training loss = 0.031928256\n",
      "Aug 03, 2022 10:11:42 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 15600, training loss = 0.09293355\n",
      "Aug 03, 2022 10:11:43 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 15700, training loss = 0.030901292\n",
      "Aug 03, 2022 10:11:45 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 15800, training loss = 0.04228763\n",
      "Aug 03, 2022 10:11:47 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 15900, training loss = 0.03136723\n",
      "Aug 03, 2022 10:11:48 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 16000, training loss = 0.032127324\n",
      "Aug 03, 2022 10:11:50 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 16100, training loss = 0.029974032\n",
      "Aug 03, 2022 10:11:51 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 16200, training loss = 0.08701065\n",
      "Aug 03, 2022 10:11:53 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 16300, training loss = 0.044448204\n",
      "Aug 03, 2022 10:11:54 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 16400, training loss = 0.060073595\n",
      "Aug 03, 2022 10:11:56 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 16500, training loss = 0.054443114\n",
      "Aug 03, 2022 10:11:57 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 16600, training loss = 0.04178778\n",
      "Aug 03, 2022 10:11:59 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 16700, training loss = 0.5545581\n",
      "Aug 03, 2022 10:12:00 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 16800, training loss = 0.18002865\n",
      "Aug 03, 2022 10:12:02 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 16900, training loss = 0.03459133\n",
      "Aug 03, 2022 10:12:04 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 17000, training loss = 0.04202885\n",
      "Aug 03, 2022 10:12:05 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 17100, training loss = 0.06224408\n",
      "Aug 03, 2022 10:12:07 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 17200, training loss = 0.2216509\n",
      "Aug 03, 2022 10:12:08 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 17300, training loss = 0.037246235\n",
      "Aug 03, 2022 10:12:10 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 17400, training loss = 0.034975614\n",
      "Aug 03, 2022 10:12:11 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 17500, training loss = 0.03129923\n",
      "Aug 03, 2022 10:12:13 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 17600, training loss = 0.15828818\n",
      "Aug 03, 2022 10:12:15 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 17700, training loss = 0.0473338\n",
      "Aug 03, 2022 10:12:16 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 17800, training loss = 0.037382502\n",
      "Aug 03, 2022 10:12:18 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 17900, training loss = 0.026308304\n",
      "Aug 03, 2022 10:12:19 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 18000, training loss = 0.033108477\n",
      "Aug 03, 2022 10:12:21 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 18100, training loss = 0.34475502\n",
      "Aug 03, 2022 10:12:23 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 18200, training loss = 0.03341214\n",
      "Aug 03, 2022 10:12:24 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 18300, training loss = 0.054214384\n",
      "Aug 03, 2022 10:12:26 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 18400, training loss = 0.027893025\n",
      "Aug 03, 2022 10:12:27 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 18500, training loss = 0.029087149\n",
      "Aug 03, 2022 10:12:29 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 18600, training loss = 0.028658684\n",
      "Aug 03, 2022 10:12:30 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 18700, training loss = 0.032624964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Aug 03, 2022 10:12:32 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 18800, training loss = 0.55106115\n",
      "Aug 03, 2022 10:12:33 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 18900, training loss = 0.030496743\n",
      "Aug 03, 2022 10:12:35 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 19000, training loss = 0.03049314\n",
      "Aug 03, 2022 10:12:37 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 19100, training loss = 0.039093934\n",
      "Aug 03, 2022 10:12:38 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 19200, training loss = 0.04146476\n",
      "Aug 03, 2022 10:12:40 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 19300, training loss = 0.11316521\n",
      "Aug 03, 2022 10:12:41 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 19400, training loss = 0.5713376\n",
      "Aug 03, 2022 10:12:43 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 19500, training loss = 0.030768227\n",
      "Aug 03, 2022 10:12:44 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 19600, training loss = 0.03217807\n",
      "Aug 03, 2022 10:12:46 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 19700, training loss = 0.44093263\n",
      "Aug 03, 2022 10:12:47 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 19800, training loss = 0.5270723\n",
      "Aug 03, 2022 10:12:49 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 19900, training loss = 0.028772686\n",
      "Aug 03, 2022 10:12:51 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 20000, training loss = 0.02983993\n",
      "Aug 03, 2022 10:12:52 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 20100, training loss = 0.03015225\n",
      "Aug 03, 2022 10:12:54 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 20200, training loss = 0.029425532\n",
      "Aug 03, 2022 10:12:55 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 20300, training loss = 0.032667127\n",
      "Aug 03, 2022 10:12:57 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 20400, training loss = 0.09978914\n",
      "Aug 03, 2022 10:12:59 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 20500, training loss = 0.030669302\n",
      "Aug 03, 2022 10:13:00 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 20600, training loss = 0.02942246\n",
      "Aug 03, 2022 10:13:02 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 20700, training loss = 0.030118091\n",
      "Aug 03, 2022 10:13:03 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 20800, training loss = 0.4243027\n",
      "Aug 03, 2022 10:13:05 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 20900, training loss = 0.034854647\n",
      "Aug 03, 2022 10:13:06 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 21000, training loss = 0.030485667\n",
      "Aug 03, 2022 10:13:08 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 21100, training loss = 0.032389663\n",
      "Aug 03, 2022 10:13:09 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 21200, training loss = 0.04437729\n",
      "Aug 03, 2022 10:13:11 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 21300, training loss = 0.14955857\n",
      "Aug 03, 2022 10:13:13 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 21400, training loss = 0.030343158\n",
      "Aug 03, 2022 10:13:14 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 21500, training loss = 0.031146107\n",
      "Aug 03, 2022 10:13:16 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 21600, training loss = 0.03329922\n",
      "Aug 03, 2022 10:13:17 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 21700, training loss = 0.07743099\n",
      "Aug 03, 2022 10:13:19 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 21800, training loss = 0.038876552\n",
      "Aug 03, 2022 10:13:21 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 21900, training loss = 0.031411342\n",
      "Aug 03, 2022 10:13:22 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 22000, training loss = 0.032051664\n",
      "Aug 03, 2022 10:13:24 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 22100, training loss = 0.031095192\n",
      "Aug 03, 2022 10:13:25 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 22200, training loss = 0.075067766\n",
      "Aug 03, 2022 10:13:27 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 22300, training loss = 0.25027132\n",
      "Aug 03, 2022 10:13:28 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 22400, training loss = 0.10866257\n",
      "Aug 03, 2022 10:13:30 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 22500, training loss = 0.27736023\n",
      "Aug 03, 2022 10:13:31 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 22600, training loss = 0.03263742\n",
      "Aug 03, 2022 10:13:33 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 22700, training loss = 0.38490084\n",
      "Aug 03, 2022 10:13:34 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 22800, training loss = 0.033495344\n",
      "Aug 03, 2022 10:13:36 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 22900, training loss = 0.256158\n",
      "Aug 03, 2022 10:13:37 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 23000, training loss = 0.03005782\n",
      "Aug 03, 2022 10:13:39 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 23100, training loss = 0.032404017\n",
      "Aug 03, 2022 10:13:41 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 23200, training loss = 0.4348962\n",
      "Aug 03, 2022 10:13:42 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 23300, training loss = 0.03412205\n",
      "Aug 03, 2022 10:13:44 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 23400, training loss = 0.03470047\n",
      "Aug 03, 2022 10:13:45 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 23500, training loss = 0.029275676\n",
      "Aug 03, 2022 10:13:47 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 23600, training loss = 0.033080615\n",
      "Aug 03, 2022 10:13:48 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 23700, training loss = 0.079500556\n",
      "Aug 03, 2022 10:13:50 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 23800, training loss = 0.029166358\n",
      "Aug 03, 2022 10:13:52 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 23900, training loss = 0.025841886\n",
      "Aug 03, 2022 10:13:53 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 24000, training loss = 0.024835395\n",
      "Aug 03, 2022 10:13:55 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 24100, training loss = 0.09357138\n",
      "Aug 03, 2022 10:13:57 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 24200, training loss = 0.04137924\n",
      "Aug 03, 2022 10:13:58 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 24300, training loss = 0.29672658\n",
      "Aug 03, 2022 10:14:00 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 24400, training loss = 0.028852824\n",
      "Aug 03, 2022 10:14:01 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 24500, training loss = 0.075984724\n",
      "Aug 03, 2022 10:14:03 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 24600, training loss = 0.028414883\n",
      "Aug 03, 2022 10:14:05 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 24700, training loss = 0.032046013\n",
      "Aug 03, 2022 10:14:06 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 24800, training loss = 0.03256623\n",
      "Aug 03, 2022 10:14:08 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 24900, training loss = 0.064641\n",
      "Aug 03, 2022 10:14:09 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 25000, training loss = 0.029152596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Aug 03, 2022 10:14:11 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 25100, training loss = 0.029258726\n",
      "Aug 03, 2022 10:14:13 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 25200, training loss = 0.028982537\n",
      "Aug 03, 2022 10:14:14 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 25300, training loss = 0.030647844\n",
      "Aug 03, 2022 10:14:16 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 25400, training loss = 0.3666283\n",
      "Aug 03, 2022 10:14:18 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 25500, training loss = 0.029868495\n",
      "Aug 03, 2022 10:14:19 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 25600, training loss = 0.02974496\n",
      "Aug 03, 2022 10:14:21 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 25700, training loss = 0.082770735\n",
      "Aug 03, 2022 10:14:22 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 25800, training loss = 1.0322543\n",
      "Aug 03, 2022 10:14:24 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 25900, training loss = 0.030925449\n",
      "Aug 03, 2022 10:14:26 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 26000, training loss = 0.04447961\n",
      "Aug 03, 2022 10:14:27 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 26100, training loss = 0.02907917\n",
      "Aug 03, 2022 10:14:29 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 26200, training loss = 0.027017286\n",
      "Aug 03, 2022 10:14:30 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 26300, training loss = 0.07078166\n",
      "Aug 03, 2022 10:14:32 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 26400, training loss = 0.06879838\n",
      "Aug 03, 2022 10:14:34 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 26500, training loss = 0.037986428\n",
      "Aug 03, 2022 10:14:35 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 26600, training loss = 0.027870156\n",
      "Aug 03, 2022 10:14:37 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 26700, training loss = 0.027930742\n",
      "Aug 03, 2022 10:14:38 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 26800, training loss = 0.026894886\n",
      "Aug 03, 2022 10:14:40 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 26900, training loss = 0.029462285\n",
      "Aug 03, 2022 10:14:42 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 27000, training loss = 0.027625166\n",
      "Aug 03, 2022 10:14:43 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 27100, training loss = 0.028252333\n",
      "Aug 03, 2022 10:14:45 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 27200, training loss = 0.21339521\n",
      "Aug 03, 2022 10:14:47 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 27300, training loss = 0.03271038\n",
      "Aug 03, 2022 10:14:48 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 27400, training loss = 0.028649535\n",
      "Aug 03, 2022 10:14:50 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 27500, training loss = 0.02889232\n",
      "Aug 03, 2022 10:14:52 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 27600, training loss = 0.028318636\n",
      "Aug 03, 2022 10:14:53 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 27700, training loss = 0.027164476\n",
      "Aug 03, 2022 10:14:55 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 27800, training loss = 0.035103206\n",
      "Aug 03, 2022 10:14:57 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 27900, training loss = 0.028424382\n",
      "Aug 03, 2022 10:14:58 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 28000, training loss = 0.031174688\n",
      "Aug 03, 2022 10:15:00 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 28100, training loss = 0.028713277\n",
      "Aug 03, 2022 10:15:02 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 28200, training loss = 0.045624983\n",
      "Aug 03, 2022 10:15:03 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 28300, training loss = 0.22052449\n",
      "Aug 03, 2022 10:15:05 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 28400, training loss = 0.030620787\n",
      "Aug 03, 2022 10:15:07 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 28500, training loss = 0.057014614\n",
      "Aug 03, 2022 10:15:09 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 28600, training loss = 0.0420457\n",
      "Aug 03, 2022 10:15:10 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 28700, training loss = 0.28627172\n",
      "Aug 03, 2022 10:15:12 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 28800, training loss = 0.0472591\n",
      "Aug 03, 2022 10:15:14 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 28900, training loss = 0.049720667\n",
      "Aug 03, 2022 10:15:15 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 29000, training loss = 0.028837316\n",
      "Aug 03, 2022 10:15:17 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 29100, training loss = 0.045707818\n",
      "Aug 03, 2022 10:15:18 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 29200, training loss = 0.6040765\n",
      "Aug 03, 2022 10:15:20 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 29300, training loss = 0.036520276\n",
      "Aug 03, 2022 10:15:22 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 29400, training loss = 0.16494143\n",
      "Aug 03, 2022 10:15:23 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 29500, training loss = 0.035558075\n",
      "Aug 03, 2022 10:15:25 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 29600, training loss = 0.027049439\n",
      "Aug 03, 2022 10:15:26 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 29700, training loss = 0.036116283\n",
      "Aug 03, 2022 10:15:28 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 29800, training loss = 0.02631331\n",
      "Aug 03, 2022 10:15:30 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 29900, training loss = 0.022917297\n",
      "Aug 03, 2022 10:15:31 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 30000, training loss = 0.022109032\n",
      "Aug 03, 2022 10:15:33 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 30100, training loss = 0.05554581\n",
      "Aug 03, 2022 10:15:34 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 30200, training loss = 0.029910859\n",
      "Aug 03, 2022 10:15:36 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 30300, training loss = 0.35187596\n",
      "Aug 03, 2022 10:15:37 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 30400, training loss = 0.02655446\n",
      "Aug 03, 2022 10:15:39 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 30500, training loss = 0.029637847\n",
      "Aug 03, 2022 10:15:41 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 30600, training loss = 0.04460154\n",
      "Aug 03, 2022 10:15:42 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 30700, training loss = 0.14118356\n",
      "Aug 03, 2022 10:15:44 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 30800, training loss = 0.5904664\n",
      "Aug 03, 2022 10:15:46 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 30900, training loss = 0.65605116\n",
      "Aug 03, 2022 10:15:47 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 31000, training loss = 0.1573263\n",
      "Aug 03, 2022 10:15:49 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 31100, training loss = 0.026936742\n",
      "Aug 03, 2022 10:15:50 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 31200, training loss = 0.027761407\n",
      "Aug 03, 2022 10:15:52 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 31300, training loss = 0.02717279\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Aug 03, 2022 10:15:54 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 31400, training loss = 0.52246344\n",
      "Aug 03, 2022 10:15:56 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 31500, training loss = 0.0264423\n",
      "Aug 03, 2022 10:15:57 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 31600, training loss = 0.02821695\n",
      "Aug 03, 2022 10:15:59 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 31700, training loss = 0.034025405\n",
      "Aug 03, 2022 10:16:01 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 31800, training loss = 0.9690399\n",
      "Aug 03, 2022 10:16:02 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 31900, training loss = 0.7269638\n",
      "Aug 03, 2022 10:16:04 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 32000, training loss = 0.024554022\n",
      "Aug 03, 2022 10:16:06 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 32100, training loss = 0.02547894\n",
      "Aug 03, 2022 10:16:08 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 32200, training loss = 0.023397228\n",
      "Aug 03, 2022 10:16:09 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 32300, training loss = 0.025661893\n",
      "Aug 03, 2022 10:16:11 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 32400, training loss = 0.2921791\n",
      "Aug 03, 2022 10:16:13 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 32500, training loss = 0.0363345\n",
      "Aug 03, 2022 10:16:14 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 32600, training loss = 0.023195904\n",
      "Aug 03, 2022 10:16:16 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 32700, training loss = 0.024082925\n",
      "Aug 03, 2022 10:16:18 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 32800, training loss = 0.026390368\n",
      "Aug 03, 2022 10:16:19 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 32900, training loss = 0.03644829\n",
      "Aug 03, 2022 10:16:21 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 33000, training loss = 0.023828365\n",
      "Aug 03, 2022 10:16:22 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 33100, training loss = 0.028721726\n",
      "Aug 03, 2022 10:16:24 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 33200, training loss = 0.025077209\n",
      "Aug 03, 2022 10:16:26 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 33300, training loss = 0.022205133\n",
      "Aug 03, 2022 10:16:27 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 33400, training loss = 0.026321176\n",
      "Aug 03, 2022 10:16:29 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 33500, training loss = 0.021728404\n",
      "Aug 03, 2022 10:16:31 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 33600, training loss = 0.023892611\n",
      "Aug 03, 2022 10:16:32 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 33700, training loss = 0.022235895\n",
      "Aug 03, 2022 10:16:34 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 33800, training loss = 0.022611097\n",
      "Aug 03, 2022 10:16:35 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 33900, training loss = 0.023785096\n",
      "Aug 03, 2022 10:16:37 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 34000, training loss = 0.021053314\n",
      "Aug 03, 2022 10:16:39 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 34100, training loss = 0.023063509\n",
      "Aug 03, 2022 10:16:40 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 34200, training loss = 0.10642093\n",
      "Aug 03, 2022 10:16:42 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 34300, training loss = 0.022110917\n",
      "Aug 03, 2022 10:16:44 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 34400, training loss = 0.21133547\n",
      "Aug 03, 2022 10:16:45 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 34500, training loss = 0.021077204\n",
      "Aug 03, 2022 10:16:47 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 34600, training loss = 0.21108346\n",
      "Aug 03, 2022 10:16:49 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 34700, training loss = 0.8790725\n",
      "Aug 03, 2022 10:16:50 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 34800, training loss = 0.053016983\n",
      "Aug 03, 2022 10:16:52 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 34900, training loss = 0.103362516\n",
      "Aug 03, 2022 10:16:53 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 35000, training loss = 0.022830639\n",
      "Aug 03, 2022 10:16:55 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 35100, training loss = 0.045535658\n",
      "Aug 03, 2022 10:16:57 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 35200, training loss = 0.022014946\n",
      "Aug 03, 2022 10:16:58 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 35300, training loss = 0.021303887\n",
      "Aug 03, 2022 10:17:00 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 35400, training loss = 0.028302988\n",
      "Aug 03, 2022 10:17:01 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 35500, training loss = 0.025361419\n",
      "Aug 03, 2022 10:17:03 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 35600, training loss = 0.020955127\n",
      "Aug 03, 2022 10:17:05 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 35700, training loss = 0.07942307\n",
      "Aug 03, 2022 10:17:06 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 35800, training loss = 0.020630512\n",
      "Aug 03, 2022 10:17:08 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 35900, training loss = 0.016780334\n",
      "Aug 03, 2022 10:17:10 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 36000, training loss = 0.016093057\n",
      "Aug 03, 2022 10:17:11 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 36100, training loss = 0.057736874\n",
      "Aug 03, 2022 10:17:13 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 36200, training loss = 0.04400103\n",
      "Aug 03, 2022 10:17:15 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 36300, training loss = 0.018652545\n",
      "Aug 03, 2022 10:17:16 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 36400, training loss = 0.02047431\n",
      "Aug 03, 2022 10:17:18 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 36500, training loss = 0.022051305\n",
      "Aug 03, 2022 10:17:19 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 36600, training loss = 0.37355763\n",
      "Aug 03, 2022 10:17:21 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 36700, training loss = 0.9054418\n",
      "Aug 03, 2022 10:17:23 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 36800, training loss = 0.021069989\n",
      "Aug 03, 2022 10:17:24 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 36900, training loss = 0.02110819\n",
      "Aug 03, 2022 10:17:26 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 37000, training loss = 0.020456433\n",
      "Aug 03, 2022 10:17:28 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 37100, training loss = 0.024567477\n",
      "Aug 03, 2022 10:17:29 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 37200, training loss = 0.12762389\n",
      "Aug 03, 2022 10:17:31 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 37300, training loss = 0.021301107\n",
      "Aug 03, 2022 10:17:32 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 37400, training loss = 1.1925511\n",
      "Aug 03, 2022 10:17:34 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 37500, training loss = 0.019368662\n",
      "Aug 03, 2022 10:17:36 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 37600, training loss = 0.02122952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Aug 03, 2022 10:17:38 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 37700, training loss = 0.027559124\n",
      "Aug 03, 2022 10:17:39 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 37800, training loss = 0.78333247\n",
      "Aug 03, 2022 10:17:41 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 37900, training loss = 0.018295053\n",
      "Aug 03, 2022 10:17:42 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 38000, training loss = 0.018625885\n",
      "Aug 03, 2022 10:17:44 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 38100, training loss = 0.01981305\n",
      "Aug 03, 2022 10:17:46 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 38200, training loss = 0.018840618\n",
      "Aug 03, 2022 10:17:47 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 38300, training loss = 0.020456152\n",
      "Aug 03, 2022 10:17:49 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 38400, training loss = 0.039390117\n",
      "Aug 03, 2022 10:17:50 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 38500, training loss = 0.019507036\n",
      "Aug 03, 2022 10:17:52 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 38600, training loss = 0.019316578\n",
      "Aug 03, 2022 10:17:54 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 38700, training loss = 0.02029004\n",
      "Aug 03, 2022 10:17:55 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 38800, training loss = 0.020385997\n",
      "Aug 03, 2022 10:17:57 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 38900, training loss = 0.01995583\n",
      "Aug 03, 2022 10:17:58 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 39000, training loss = 0.021136155\n",
      "Aug 03, 2022 10:18:00 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 39100, training loss = 0.021204684\n",
      "Aug 03, 2022 10:18:02 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 39200, training loss = 0.1677515\n",
      "Aug 03, 2022 10:18:03 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 39300, training loss = 0.028505515\n",
      "Aug 03, 2022 10:18:05 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 39400, training loss = 0.020222608\n",
      "Aug 03, 2022 10:18:06 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 39500, training loss = 0.020349137\n",
      "Aug 03, 2022 10:18:08 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 39600, training loss = 0.02701898\n",
      "Aug 03, 2022 10:18:10 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 39700, training loss = 0.48049283\n",
      "Aug 03, 2022 10:18:11 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 39800, training loss = 0.021949079\n",
      "Aug 03, 2022 10:18:13 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 39900, training loss = 0.01935768\n",
      "Aug 03, 2022 10:18:14 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 40000, training loss = 0.020075288\n",
      "Aug 03, 2022 10:18:16 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 40100, training loss = 0.13089779\n",
      "Aug 03, 2022 10:18:18 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 40200, training loss = 0.04835332\n",
      "Aug 03, 2022 10:18:19 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 40300, training loss = 0.02102838\n",
      "Aug 03, 2022 10:18:21 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 40400, training loss = 0.018792832\n",
      "Aug 03, 2022 10:18:22 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 40500, training loss = 0.05168634\n",
      "Aug 03, 2022 10:18:24 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 40600, training loss = 0.021485902\n",
      "Aug 03, 2022 10:18:26 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 40700, training loss = 0.71086556\n",
      "Aug 03, 2022 10:18:28 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 40800, training loss = 0.54657596\n",
      "Aug 03, 2022 10:18:29 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 40900, training loss = 0.2175074\n",
      "Aug 03, 2022 10:18:31 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 41000, training loss = 0.034314483\n",
      "Aug 03, 2022 10:18:32 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 41100, training loss = 0.03339454\n",
      "Aug 03, 2022 10:18:34 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 41200, training loss = 0.17576176\n",
      "Aug 03, 2022 10:18:36 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 41300, training loss = 0.042526625\n",
      "Aug 03, 2022 10:18:37 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 41400, training loss = 0.023060562\n",
      "Aug 03, 2022 10:18:39 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 41500, training loss = 0.019956445\n",
      "Aug 03, 2022 10:18:40 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 41600, training loss = 0.037980586\n",
      "Aug 03, 2022 10:18:42 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 41700, training loss = 0.040153608\n",
      "Aug 03, 2022 10:18:43 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 41800, training loss = 0.02260223\n",
      "Aug 03, 2022 10:18:45 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 41900, training loss = 0.015714718\n",
      "Aug 03, 2022 10:18:47 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 42000, training loss = 0.0148053\n",
      "Aug 03, 2022 10:18:48 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 42100, training loss = 0.10387315\n",
      "Aug 03, 2022 10:18:50 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 42200, training loss = 0.054275747\n",
      "Aug 03, 2022 10:18:52 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 42300, training loss = 0.09492024\n",
      "Aug 03, 2022 10:18:53 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 42400, training loss = 0.19058466\n",
      "Aug 03, 2022 10:18:55 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 42500, training loss = 0.027082106\n",
      "Aug 03, 2022 10:18:56 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 42600, training loss = 0.20145589\n",
      "Aug 03, 2022 10:18:58 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 42700, training loss = 0.08745466\n",
      "Aug 03, 2022 10:18:59 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 42800, training loss = 0.280578\n",
      "Aug 03, 2022 10:19:01 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 42900, training loss = 0.018647801\n",
      "Aug 03, 2022 10:19:03 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 43000, training loss = 0.018338777\n",
      "Aug 03, 2022 10:19:04 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 43100, training loss = 0.021087375\n",
      "Aug 03, 2022 10:19:06 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 43200, training loss = 0.08099362\n",
      "Aug 03, 2022 10:19:07 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 43300, training loss = 0.022572363\n",
      "Aug 03, 2022 10:19:09 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 43400, training loss = 0.38235494\n",
      "Aug 03, 2022 10:19:11 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 43500, training loss = 0.018060254\n",
      "Aug 03, 2022 10:19:12 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 43600, training loss = 0.018315546\n",
      "Aug 03, 2022 10:19:14 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 43700, training loss = 0.3343342\n",
      "Aug 03, 2022 10:19:15 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 43800, training loss = 1.6353859\n",
      "Aug 03, 2022 10:19:17 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 43900, training loss = 0.025659686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Aug 03, 2022 10:19:19 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 44000, training loss = 0.017995887\n",
      "Aug 03, 2022 10:19:20 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 44100, training loss = 0.02008864\n",
      "Aug 03, 2022 10:19:22 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 44200, training loss = 0.017961688\n",
      "Aug 03, 2022 10:19:23 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 44300, training loss = 0.018459242\n",
      "Aug 03, 2022 10:19:25 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 44400, training loss = 0.5893866\n",
      "Aug 03, 2022 10:19:27 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 44500, training loss = 0.018900836\n",
      "Aug 03, 2022 10:19:28 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 44600, training loss = 0.018247832\n",
      "Aug 03, 2022 10:19:30 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 44700, training loss = 0.01865707\n",
      "Aug 03, 2022 10:19:31 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 44800, training loss = 0.018074762\n",
      "Aug 03, 2022 10:19:33 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 44900, training loss = 0.02012745\n",
      "Aug 03, 2022 10:19:35 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 45000, training loss = 0.018829407\n",
      "Aug 03, 2022 10:19:36 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 45100, training loss = 0.019396983\n",
      "Aug 03, 2022 10:19:38 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 45200, training loss = 0.022406194\n",
      "Aug 03, 2022 10:19:39 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 45300, training loss = 0.019599063\n",
      "Aug 03, 2022 10:19:41 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 45400, training loss = 0.018175988\n",
      "Aug 03, 2022 10:19:43 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 45500, training loss = 0.018565832\n",
      "Aug 03, 2022 10:19:44 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 45600, training loss = 0.042347096\n",
      "Aug 03, 2022 10:19:46 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 45700, training loss = 0.06722693\n",
      "Aug 03, 2022 10:19:47 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 45800, training loss = 0.062538825\n",
      "Aug 03, 2022 10:19:49 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 45900, training loss = 0.017798595\n",
      "Aug 03, 2022 10:19:51 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 46000, training loss = 0.01790129\n",
      "Aug 03, 2022 10:19:52 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 46100, training loss = 0.025237985\n",
      "Aug 03, 2022 10:19:54 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 46200, training loss = 0.25804955\n",
      "Aug 03, 2022 10:19:55 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 46300, training loss = 0.018554427\n",
      "Aug 03, 2022 10:19:57 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 46400, training loss = 0.017553922\n",
      "Aug 03, 2022 10:19:59 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 46500, training loss = 0.017978176\n",
      "Aug 03, 2022 10:20:00 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 46600, training loss = 0.019808885\n",
      "Aug 03, 2022 10:20:02 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 46700, training loss = 0.19885674\n",
      "Aug 03, 2022 10:20:03 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 46800, training loss = 0.11024237\n",
      "Aug 03, 2022 10:20:05 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 46900, training loss = 0.1127132\n",
      "Aug 03, 2022 10:20:07 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 47000, training loss = 0.029252535\n",
      "Aug 03, 2022 10:20:08 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 47100, training loss = 0.02651235\n",
      "Aug 03, 2022 10:20:10 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 47200, training loss = 0.8978327\n",
      "Aug 03, 2022 10:20:11 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 47300, training loss = 0.020235078\n",
      "Aug 03, 2022 10:20:13 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 47400, training loss = 0.02700324\n",
      "Aug 03, 2022 10:20:15 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 47500, training loss = 0.019259889\n",
      "Aug 03, 2022 10:20:16 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 47600, training loss = 0.018260911\n",
      "Aug 03, 2022 10:20:18 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 47700, training loss = 0.065530084\n",
      "Aug 03, 2022 10:20:20 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 47800, training loss = 0.017377514\n",
      "Aug 03, 2022 10:20:21 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 47900, training loss = 0.014189416\n",
      "Aug 03, 2022 10:20:23 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 48000, training loss = 0.014052534\n",
      "Aug 03, 2022 10:20:24 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 48100, training loss = 0.03552112\n",
      "Aug 03, 2022 10:20:26 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 48200, training loss = 0.024261763\n",
      "Aug 03, 2022 10:20:27 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 48300, training loss = 0.02155276\n",
      "Aug 03, 2022 10:20:29 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 48400, training loss = 0.01799752\n",
      "Aug 03, 2022 10:20:31 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 48500, training loss = 0.0513246\n",
      "Aug 03, 2022 10:20:32 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 48600, training loss = 0.09033285\n",
      "Aug 03, 2022 10:20:34 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 48700, training loss = 0.017911937\n",
      "Aug 03, 2022 10:20:36 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 48800, training loss = 0.33726484\n",
      "Aug 03, 2022 10:20:37 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 48900, training loss = 0.018310731\n",
      "Aug 03, 2022 10:20:39 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 49000, training loss = 0.018330567\n",
      "Aug 03, 2022 10:20:41 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 49100, training loss = 0.026445586\n",
      "Aug 03, 2022 10:20:42 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 49200, training loss = 0.018317157\n",
      "Aug 03, 2022 10:20:44 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 49300, training loss = 0.018916665\n",
      "Aug 03, 2022 10:20:46 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 49400, training loss = 0.5343079\n",
      "Aug 03, 2022 10:20:47 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 49500, training loss = 0.018984111\n",
      "Aug 03, 2022 10:20:49 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 49600, training loss = 0.020302158\n",
      "Aug 03, 2022 10:20:50 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 49700, training loss = 0.019411014\n",
      "Aug 03, 2022 10:20:52 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 49800, training loss = 1.0637854\n",
      "Aug 03, 2022 10:20:54 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 49900, training loss = 0.07002592\n",
      "Aug 03, 2022 10:20:55 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 50000, training loss = 0.020821974\n",
      "Aug 03, 2022 10:20:57 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 50100, training loss = 0.031015646\n",
      "Aug 03, 2022 10:20:59 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 50200, training loss = 0.01767958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Aug 03, 2022 10:21:00 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 50300, training loss = 0.10993437\n",
      "Aug 03, 2022 10:21:02 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 50400, training loss = 0.02694911\n",
      "Aug 03, 2022 10:21:03 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 50500, training loss = 0.020752639\n",
      "Aug 03, 2022 10:21:05 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 50600, training loss = 0.01825488\n",
      "Aug 03, 2022 10:21:07 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 50700, training loss = 0.023670116\n",
      "Aug 03, 2022 10:21:08 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 50800, training loss = 0.017575016\n",
      "Aug 03, 2022 10:21:10 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 50900, training loss = 0.03584523\n",
      "Aug 03, 2022 10:21:11 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 51000, training loss = 0.018939907\n",
      "Aug 03, 2022 10:21:13 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 51100, training loss = 0.021671126\n",
      "Aug 03, 2022 10:21:15 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 51200, training loss = 0.020682475\n",
      "Aug 03, 2022 10:21:16 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 51300, training loss = 0.051517345\n",
      "Aug 03, 2022 10:21:18 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 51400, training loss = 0.018884024\n",
      "Aug 03, 2022 10:21:19 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 51500, training loss = 0.01888107\n",
      "Aug 03, 2022 10:21:21 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 51600, training loss = 0.28136113\n",
      "Aug 03, 2022 10:21:23 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 51700, training loss = 0.042106383\n",
      "Aug 03, 2022 10:21:24 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 51800, training loss = 0.048484184\n",
      "Aug 03, 2022 10:21:26 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 51900, training loss = 0.018024018\n",
      "Aug 03, 2022 10:21:28 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 52000, training loss = 0.018581245\n",
      "Aug 03, 2022 10:21:30 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 52100, training loss = 0.10621865\n",
      "Aug 03, 2022 10:21:31 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 52200, training loss = 0.024915565\n",
      "Aug 03, 2022 10:21:33 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 52300, training loss = 0.028444974\n",
      "Aug 03, 2022 10:21:34 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 52400, training loss = 0.017485464\n",
      "Aug 03, 2022 10:21:36 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 52500, training loss = 0.017886328\n",
      "Aug 03, 2022 10:21:38 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 52600, training loss = 0.061831586\n",
      "Aug 03, 2022 10:21:39 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 52700, training loss = 0.19684422\n",
      "Aug 03, 2022 10:21:41 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 52800, training loss = 0.3092292\n",
      "Aug 03, 2022 10:21:42 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 52900, training loss = 0.67286474\n",
      "Aug 03, 2022 10:21:44 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 53000, training loss = 0.019662242\n",
      "Aug 03, 2022 10:21:46 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 53100, training loss = 0.041522216\n",
      "Aug 03, 2022 10:21:47 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 53200, training loss = 0.04281782\n",
      "Aug 03, 2022 10:21:49 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 53300, training loss = 0.01911023\n",
      "Aug 03, 2022 10:21:50 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 53400, training loss = 0.02536178\n",
      "Aug 03, 2022 10:21:52 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 53500, training loss = 0.019493528\n",
      "Aug 03, 2022 10:21:54 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 53600, training loss = 0.019133396\n",
      "Aug 03, 2022 10:21:55 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 53700, training loss = 0.09902105\n",
      "Aug 03, 2022 10:21:57 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 53800, training loss = 0.019492876\n",
      "Aug 03, 2022 10:21:58 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 53900, training loss = 0.015377528\n",
      "Aug 03, 2022 10:22:00 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 54000, training loss = 0.01591161\n",
      "Aug 03, 2022 10:22:02 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 54100, training loss = 1.5361526\n",
      "Aug 03, 2022 10:22:03 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 54200, training loss = 0.020242902\n",
      "Aug 03, 2022 10:22:05 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 54300, training loss = 0.54563063\n",
      "Aug 03, 2022 10:22:06 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 54400, training loss = 0.4141708\n",
      "Aug 03, 2022 10:22:08 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 54500, training loss = 0.091831505\n",
      "Aug 03, 2022 10:22:10 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 54600, training loss = 0.5706408\n",
      "Aug 03, 2022 10:22:11 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 54700, training loss = 0.019253315\n",
      "Aug 03, 2022 10:22:13 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 54800, training loss = 0.06407297\n",
      "Aug 03, 2022 10:22:15 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 54900, training loss = 0.01973622\n",
      "Aug 03, 2022 10:22:16 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 55000, training loss = 0.054390527\n",
      "Aug 03, 2022 10:22:18 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 55100, training loss = 0.080816664\n",
      "Aug 03, 2022 10:22:19 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 55200, training loss = 0.021164142\n",
      "Aug 03, 2022 10:22:21 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 55300, training loss = 0.023492072\n",
      "Aug 03, 2022 10:22:23 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 55400, training loss = 0.67127615\n",
      "Aug 03, 2022 10:22:24 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 55500, training loss = 0.019895233\n",
      "Aug 03, 2022 10:22:26 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 55600, training loss = 0.028181534\n",
      "Aug 03, 2022 10:22:28 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 55700, training loss = 0.040884778\n",
      "Aug 03, 2022 10:22:29 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 55800, training loss = 1.2160277\n",
      "Aug 03, 2022 10:22:31 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 55900, training loss = 0.02427165\n",
      "Aug 03, 2022 10:22:32 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 56000, training loss = 0.019663706\n",
      "Aug 03, 2022 10:22:34 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 56100, training loss = 0.02033374\n",
      "Aug 03, 2022 10:22:36 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 56200, training loss = 0.018789135\n",
      "Aug 03, 2022 10:22:37 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 56300, training loss = 0.019664008\n",
      "Aug 03, 2022 10:22:39 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 56400, training loss = 0.19722931\n",
      "Aug 03, 2022 10:22:40 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 56500, training loss = 0.028297175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Aug 03, 2022 10:22:42 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 56600, training loss = 0.019667719\n",
      "Aug 03, 2022 10:22:44 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 56700, training loss = 0.020502236\n",
      "Aug 03, 2022 10:22:45 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 56800, training loss = 0.019706992\n",
      "Aug 03, 2022 10:22:47 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 56900, training loss = 0.021493241\n",
      "Aug 03, 2022 10:22:48 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 57000, training loss = 0.021584123\n",
      "Aug 03, 2022 10:22:50 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 57100, training loss = 0.020970136\n",
      "Aug 03, 2022 10:22:52 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 57200, training loss = 0.033715554\n",
      "Aug 03, 2022 10:22:53 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 57300, training loss = 0.05503755\n",
      "Aug 03, 2022 10:22:55 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 57400, training loss = 0.019738207\n",
      "Aug 03, 2022 10:22:56 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 57500, training loss = 0.020072322\n",
      "Aug 03, 2022 10:22:58 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 57600, training loss = 0.2123524\n",
      "Aug 03, 2022 10:23:00 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 57700, training loss = 0.02349408\n",
      "Aug 03, 2022 10:23:01 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 57800, training loss = 0.04079003\n",
      "Aug 03, 2022 10:23:03 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 57900, training loss = 0.055801548\n",
      "Aug 03, 2022 10:23:04 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 58000, training loss = 0.020041483\n",
      "Aug 03, 2022 10:23:06 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 58100, training loss = 0.74306536\n",
      "Aug 03, 2022 10:23:08 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 58200, training loss = 0.04071865\n",
      "Aug 03, 2022 10:23:09 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 58300, training loss = 0.02937597\n",
      "Aug 03, 2022 10:23:11 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 58400, training loss = 0.019873459\n",
      "Aug 03, 2022 10:23:13 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 58500, training loss = 0.01903805\n",
      "Aug 03, 2022 10:23:14 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 58600, training loss = 0.0917733\n",
      "Aug 03, 2022 10:23:16 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 58700, training loss = 0.05102327\n",
      "Aug 03, 2022 10:23:17 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 58800, training loss = 0.474652\n",
      "Aug 03, 2022 10:23:19 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 58900, training loss = 0.62945414\n",
      "Aug 03, 2022 10:23:21 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 59000, training loss = 0.023458878\n",
      "Aug 03, 2022 10:23:22 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 59100, training loss = 0.019761516\n",
      "Aug 03, 2022 10:23:24 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 59200, training loss = 0.021676756\n",
      "Aug 03, 2022 10:23:25 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 59300, training loss = 0.021376438\n",
      "Aug 03, 2022 10:23:27 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 59400, training loss = 0.019237973\n",
      "Aug 03, 2022 10:23:29 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 59500, training loss = 0.019122187\n",
      "Aug 03, 2022 10:23:30 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 59600, training loss = 0.018173305\n",
      "Aug 03, 2022 10:23:32 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 59700, training loss = 0.08356907\n",
      "Aug 03, 2022 10:23:33 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 59800, training loss = 0.019716904\n",
      "Aug 03, 2022 10:23:35 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist train\n",
      "INFO: Iteration = 59900, training loss = 0.017735833\n",
      "Aug 03, 2022 10:23:37 PM com.twosigma.beaker.javash.bkr572f4c5e.BeakerWrapperClass1261714175Id967e7e312e6f4edb8e5ba46c66cd30d6 beakerRun\n",
      "INFO: Trained model\n",
      "Aug 03, 2022 10:23:40 PM com.twosigma.beaker.javash.bkr572f4c5e.CnnMnist test\n",
      "INFO: Final accuracy = 0.9599\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label    0    1    2    3    4    5    6    7    8    9\n",
      "    0  952    0    1    0    0    0   25    0    1    1\n",
      "    1    0 1099   11    1    7    1    9    0    7    0\n",
      "    2   18    4  980    5    1    0   13    3    6    2\n",
      "    3    0    1    3  980    0   11    6    5    1    3\n",
      "    4    2    2    1    0  952    0   10    0    0   15\n",
      "    5    3    2    0    9    1  858    8    1    2    8\n",
      "    6    4    2    0    0    1    5  945    0    1    0\n",
      "    7    0   21   23    9    4    0    4  946    3   18\n",
      "    8    2    0    4   28   10    1   14    1  904   10\n",
      "    9    5    2    2    4    4    0    2    3    4  983\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "null"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import java.util.logging.Logger;\n",
    "import org.tensorflow.Graph;\n",
    "import org.tensorflow.Session;\n",
    "import java.nio.file.Paths;\n",
    "import java.lang.*;\n",
    "\n",
    "int epochs = 10;\n",
    "int minibatchSize = 10;\n",
    "\n",
    "String currentDirectory = Paths.get(\"\").toAbsolutePath().toString() + \"/\";\n",
    "System.out.println(\"Current directory: \" + currentDirectory);\n",
    "\n",
    "final String TRAINING_IMAGES_ARCHIVE = currentDirectory + \"mnist-dataset/train-images-idx3-ubyte.gz\";\n",
    "final String TRAINING_LABELS_ARCHIVE = currentDirectory + \"mnist-dataset/train-labels-idx1-ubyte.gz\";\n",
    "final String TEST_IMAGES_ARCHIVE = currentDirectory + \"mnist-dataset/t10k-images-idx3-ubyte.gz\";\n",
    "final String TEST_LABELS_ARCHIVE = currentDirectory + \"mnist-dataset/t10k-labels-idx1-ubyte.gz\";\n",
    "\n",
    "Logger logger = Logger.getLogger(\"Main logger\");\n",
    "MnistDataset dataset = MnistDataset.create(0, TRAINING_IMAGES_ARCHIVE, TRAINING_LABELS_ARCHIVE, TEST_IMAGES_ARCHIVE, TEST_LABELS_ARCHIVE);\n",
    "\n",
    "logger.info(\"Loaded data.\");\n",
    "\n",
    "try (Graph graph = CnnMnist.build(\"RMSProp\");    \n",
    "  Session session = new Session(graph)) {\n",
    "  CnnMnist.train(session, epochs, minibatchSize, dataset);\n",
    "\n",
    "  logger.info(\"Trained model\");\n",
    "\n",
    "  CnnMnist.test(session, minibatchSize, dataset);\n",
    "} catch (Exception e) {\n",
    "    System.out.println(e);\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6deabc0e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Java",
   "language": "java",
   "name": "java"
  },
  "language_info": {
   "codemirror_mode": "text/x-java",
   "file_extension": ".java",
   "mimetype": "",
   "name": "Java",
   "nbconverter_exporter": "",
   "version": "1.8.0_121"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": false,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
